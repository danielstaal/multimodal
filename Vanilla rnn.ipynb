{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import json\n",
    "import pprint\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "file = np.load('merged_train.npy')\n",
    "x = file[0:1000]\n",
    "with open('merged_train.json') as data_file:    \n",
    "    data = json.load(data_file)\n",
    "y = data[0:1000]\n",
    "\n",
    "n = int(0.9*len(x))\n",
    "train_x = x[:n]\n",
    "test_x = x[n:]\n",
    "\n",
    "train_y = y[:n]\n",
    "test_y = y[n:]\n",
    "\n",
    "f = open('sample_merged_train.json','w')\n",
    "for item in y:\n",
    "    f.write(\"%s\\n\" % item)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = []\n",
    "# y = []\n",
    "# for i in xrange(1, 50):\n",
    "#     x.append([0] * i)\n",
    "#     y.append(0)\n",
    "#     k = random.randint(0, len(x[-1]) - 1)\n",
    "#     x.append(list(x[-1]))\n",
    "#     x[-1][k] = 1\n",
    "#     y.append(1)\n",
    "\n",
    "# zipped = zip(x, y)\n",
    "# random.shuffle(zipped)\n",
    "# x, y = zip(*zipped)\n",
    "# n = int(0.9 * len(zipped))\n",
    "\n",
    "# train_x, train_y = x[:n], y[:n]\n",
    "# test_x, test_y = x[n:], y[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1. ...,  0.  0.  0.]\n",
      "(array([2], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "a = {}\n",
    "for captions in data:\n",
    "    for sen in captions:\n",
    "        for word in sen[1]:\n",
    "            if not word in a:\n",
    "                a[word] = len(a)\n",
    "\n",
    "def num_to_vec(num):\n",
    "    vec = np.zeros(len(a))\n",
    "    vec[num] = 1\n",
    "    return vec\n",
    "    \n",
    "def vec_to_num(vec):\n",
    "    return np.where(vec == 1)\n",
    "    \n",
    "vec = num_to_vec(2)\n",
    "print vec\n",
    "print vec_to_num(vec) \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'data/datasets/mscoco/train2014/COCO_train2014_000000191666.jpg', [[u'A', u'white', u'sink', u'sitting', u'next', u'to', u'a', u'toilet', u'in', u'a', u'bathroom', u'.'], [u'A', u'bathroom', u'has', u'a', u'sink', u',', u'toilet', u'and', u'an', u'orange', u'bucket', u'in', u'it', u'.'], [u'A', u'very', u'dingy', u'looking', u'tiled', u'bathroom', u'with', u'a', u'sink', u'and', u'toilet', u'.'], [u'A', u'small', u'bathroom', u'with', u'a', u'commode', u'and', u'sink', u',', u'and', u'empty', u'corner', u'.'], [u'A', u'bathroom', u'scene', u'looking', u'at', u'the', u'toilet', u'and', u'the', u'sink', u'.']]]\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "\n",
    "class EmbeddingLayer(object):\n",
    "    def __init__(self, embedding_init):\n",
    "        self.embedding_matrix = theano.shared(embedding_init())\n",
    "\n",
    "    def get_output_expr(self, input_expr):\n",
    "        return self.embedding_matrix[input_expr]\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return [self.embedding_matrix]\n",
    "\n",
    "\n",
    "class RnnLayer(object):\n",
    "    def __init__(self, w_init, u_init):\n",
    "        self.W = theano.shared(w_init())\n",
    "        self.U = theano.shared(u_init())\n",
    "\n",
    "    def get_output_expr(self, input_sequence):\n",
    "        h0 = T.zeros((self.W.shape[0], ))\n",
    "\n",
    "        h, _ = theano.scan(fn=self.__get_rnn_step_expr,\n",
    "                           sequences=input_sequence,\n",
    "                           outputs_info=[h0])\n",
    "        return h\n",
    "\n",
    "    def __get_rnn_step_expr(self, x_t, h_tm1):\n",
    "        return T.tanh(T.dot(h_tm1, self.W) + T.dot(x_t, self.U))\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return [self.W, self.U]\n",
    "\n",
    "    \n",
    "class LogisticRegresion(object):\n",
    "    def __init__(self, w_init):\n",
    "        self.W = theano.shared(w_init())\n",
    "        \n",
    "    def get_output_expr(self, input_expr):\n",
    "        pre_softmax_expr = T.dot(input_expr, self.W)\n",
    "        return 1 / (1 + T.exp(pre_softmax_expr))\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return [self.W]\n",
    "    \n",
    "\n",
    "def get_sgd_updates(cost, params, lr=0.01):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        updates.append([p, p - lr * g])\n",
    "    return updates    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_init():\n",
    "    return np.random.randn(2, 30) * 0.01\n",
    "\n",
    "\n",
    "def w_init():\n",
    "    shape = (50, 50)\n",
    "    a = np.random.normal(0.0, 1.0, shape)\n",
    "    u, _, v = np.linalg.svd(a, full_matrices=False)\n",
    "    q = u if u.shape == shape else v\n",
    "    q = q.reshape(shape)\n",
    "    return q\n",
    "\n",
    "\n",
    "def u_init():\n",
    "    shape = (30, 50)\n",
    "    a = np.random.normal(0.0, 1.0, shape)\n",
    "    u, _, v = np.linalg.svd(a, full_matrices=False)\n",
    "    q = u if u.shape == shape else v\n",
    "    q = q.reshape(shape)\n",
    "    return q\n",
    "\n",
    "\n",
    "def lr_init():\n",
    "    return np.random.randn(50, ) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_layer = EmbeddingLayer(embedding_init)\n",
    "rnn_layer = RnnLayer(w_init, u_init)\n",
    "lr_layer = LogisticRegresion(lr_init)\n",
    "\n",
    "x = T.ivector()\n",
    "y = T.iscalar()\n",
    "\n",
    "embedding_expr = embedding_layer.get_output_expr(x)\n",
    "h = rnn_layer.get_output_expr(embedding_expr)\n",
    "py_x = lr_layer.get_output_expr(h[-1])\n",
    "y_pred = py_x > 0.5\n",
    "cost = - y * T.log(py_x) - (1 - y) * T.log(1 - py_x)\n",
    "updates = get_sgd_updates(cost, embedding_layer.get_parameters() + rnn_layer.get_parameters() + lr_layer.get_parameters())\n",
    "train = theano.function(inputs=[x, y], outputs=[cost, y_pred], updates=updates)\n",
    "val = theano.function(inputs=[x, y], outputs=[cost, y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.693215767513 0.443181818182\n",
      "val 0.693036590717 0.6\n",
      "==========\n",
      "train 0.692979501226 0.570786516854\n",
      "val 0.692876996459 0.6\n",
      "==========\n",
      "train 0.691819893263 0.64606741573\n",
      "val 0.694239695534 0.7\n",
      "==========\n",
      "train 0.687858924202 0.649438202247\n",
      "val 0.677053153522 0.7\n",
      "==========\n",
      "train 0.682752450496 0.648314606742\n",
      "val 0.671618472911 0.8\n",
      "==========\n",
      "train 0.662944292238 0.644943820225\n",
      "val 0.586331701819 0.8\n",
      "==========\n",
      "train 0.582054697441 0.683146067416\n",
      "val 0.556527845575 0.7\n",
      "==========\n",
      "train 0.53093086389 0.678651685393\n",
      "val 0.0636801815673 1.0\n",
      "==========\n",
      "train 0.0378262450133 1.0\n",
      "val 0.010604075849 1.0\n",
      "==========\n",
      "train 0.0124854511144 1.0\n",
      "val 0.00480963121226 1.0\n",
      "==========\n",
      "train 0.00708380399513 1.0\n",
      "val 0.00293775584037 1.0\n",
      "==========\n",
      "train 0.00483066641129 1.0\n",
      "val 0.00205825514487 1.0\n",
      "==========\n",
      "train 0.00361077478305 1.0\n",
      "val 0.00155974550429 1.0\n",
      "==========\n",
      "train 0.00285271189702 1.0\n",
      "val 0.00124322888744 1.0\n",
      "==========\n",
      "train 0.00233962257723 1.0\n",
      "val 0.00102638603026 1.0\n",
      "==========\n",
      "train 0.0019714200065 1.0\n",
      "val 0.000869520665428 1.0\n",
      "==========\n",
      "train 0.00169563713856 1.0\n",
      "val 0.000751316610229 1.0\n",
      "==========\n",
      "train 0.00148218914993 1.0\n",
      "val 0.000659375743889 1.0\n",
      "==========\n",
      "train 0.00131263354708 1.0\n",
      "val 0.000586027993117 1.0\n",
      "==========\n",
      "train 0.00117506310306 1.0\n",
      "val 0.000526289477411 1.0\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "c = []\n",
    "acc = []\n",
    "for i in xrange(200):\n",
    "    for x_datum, y_datum in zip(train_x, train_y):\n",
    "        a, b = train(x_datum, y_datum)\n",
    "        c.append(a)\n",
    "        acc.append(b == y_datum)\n",
    "    if i % 10 == 0:\n",
    "        print 'train', np.mean(c), np.mean(acc)\n",
    "        c = []\n",
    "        acc = []\n",
    "        for x_datum, y_datum in zip(test_x, test_y):\n",
    "            a, b = val(x_datum, y_datum)\n",
    "            c.append(a)\n",
    "            acc.append(b == y_datum)\n",
    "        print 'val', np.mean(c), np.mean(acc)\n",
    "        print '=' * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
